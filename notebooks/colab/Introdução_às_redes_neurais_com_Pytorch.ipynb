{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introdução às redes neurais com Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPX/8ohJ5nK3ItHW0bLadZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/H2IA/escola-de-verao-2021/blob/main/Introdu%C3%A7%C3%A3o_%C3%A0s_redes_neurais_com_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHWLzCQUoInO"
      },
      "source": [
        "# Introdução às redes neurais com PyTorch\r\n",
        "\r\n",
        "O PyTorch é um *framework* para *deep learning* desenvolvido para linguagem Python baseado no Torch, originalmente implementando em linguagme Lua. De modo similar do TensorFlow, o PyTorch permite a criação de redes neurais profundas tanto de forma **declarativa** (útil para usuários iniciantes) quanto **imperativa** (útil para usuários mais avançados)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOTv6Is68uUy"
      },
      "source": [
        "## Tensores\r\n",
        "\r\n",
        "As operações realizadas pelo PyTorch devem utilizar a classe `torch.tensor` como base, que fornece uma interface similar à classe `numpy.array`. É possível criar um novo objeto de tensor a partir de listas em *arrays* do `numpy` de forma simples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4faxgkaszwS"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCdGUth47n4J",
        "outputId": "f2d44847-6e53-4b3d-e8e3-7b597b103f71"
      },
      "source": [
        "data = [[1,2], [3,4]]\r\n",
        "x_data = torch.tensor(data)\r\n",
        "x_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzSGGR8H7n1J",
        "outputId": "808cb678-cdb2-40f1-9608-7d5ee4497875"
      },
      "source": [
        "data_array = np.array(data)\r\n",
        "x_data = torch.from_numpy(data_array)\r\n",
        "x_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhIJp9-xAHKP"
      },
      "source": [
        "*Slicing* de tensores usando a sintaxe do numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vu74RNt9o-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884b6789-5e6b-48b0-9808-970f38e879ea"
      },
      "source": [
        "data_array[:, 1] "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWqDOuTkAKev"
      },
      "source": [
        "Operações com tensores são \"*element-wise*\"\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP12LquB9swe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec8706c-c68d-438c-db73-ec430f257992"
      },
      "source": [
        "data_array * 1000"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1000, 2000],\n",
              "       [3000, 4000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxrr9SdH_cv4"
      },
      "source": [
        "Também podemos criar tensores com \"forma\" (*shape*) pré-definida contendo valores fixos (ex: 0 ou 1) ou aleatórios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0t5GIr67nyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6601ccf7-42f9-49a1-bff0-9eb637177452"
      },
      "source": [
        "shape = (3,2,1)\r\n",
        "\r\n",
        "x_data_random = torch.rand(shape)\r\n",
        "print('random:', x_data_random)\r\n",
        "\r\n",
        "x_data_ones   = torch.ones(shape)\r\n",
        "print('ones:', x_data_ones)\r\n",
        "\r\n",
        "x_data_zeros  = torch.zeros(shape)\r\n",
        "print('zeros:', x_data_zeros)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random: tensor([[[0.5164],\n",
            "         [0.9777]],\n",
            "\n",
            "        [[0.9778],\n",
            "         [0.8959]],\n",
            "\n",
            "        [[0.0886],\n",
            "         [0.5184]]])\n",
            "ones: tensor([[[1.],\n",
            "         [1.]],\n",
            "\n",
            "        [[1.],\n",
            "         [1.]],\n",
            "\n",
            "        [[1.],\n",
            "         [1.]]])\n",
            "zeros: tensor([[[0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaRFi2nT_t5A"
      },
      "source": [
        "Um grande diferencial dos tensores do `pytorch` em relação aos arrays do `numpy` é a sua afinidade com unidades de processamento (ex: CPU, GPU)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6iwlz7h7nnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff981dd-aafa-4557-bf50-f58e39251a1c"
      },
      "source": [
        "print('tensor shape:             ', x_data.shape)\r\n",
        "print('tensor data type (dtype): ', x_data.dtype)\r\n",
        "print('tensor device           : ', x_data.device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor shape:              torch.Size([2, 2])\n",
            "tensor data type (dtype):  torch.int64\n",
            "tensor device           :  cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1hmROMf7ncQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88eb9b0a-265d-4b1c-807f-515add70705c"
      },
      "source": [
        "if torch.cuda.is_available():\r\n",
        "  x_data_random = x_data_random.to('cuda')\r\n",
        "\r\n",
        "print('tensor device           : ', x_data_random.device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor device           :  cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upVbh6LOpcXU"
      },
      "source": [
        "## Obtendo o *dataset*\r\n",
        "\r\n",
        "Para exemplificar o uso do PyTorch na criação de redes neurais vamos retoma o exemplo do dataset de dígitos escritos à mão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0NpmKYGlnth"
      },
      "source": [
        "from sklearn.datasets import load_digits\r\n",
        "import pandas as pd"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccwZbCX8Ng-Y"
      },
      "source": [
        "data = load_digits()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3N8BtJ93zDK"
      },
      "source": [
        "X, y = data['data'], data['target']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPFW5aI4E-Ye"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def plot_digit(digit):\r\n",
        "  plt.figure(1, figsize=(3, 3))\r\n",
        "  plt.imshow(digit.reshape(8,8), cmap=plt.cm.gray_r, interpolation='nearest')\r\n",
        "  plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "QquViXz6lqUM",
        "outputId": "80a9504f-8dc1-4d33-c692-e194b14e7064"
      },
      "source": [
        "plot_digit(X[100])\r\n",
        "print('label:', y[100])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4RiXZbPkm8J"
      },
      "source": [
        "Para treinarmos um modelo com classificação multi-classe é importante garantir que todas as classes sejam representadas na mesma proporção."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKh-Uzt76Wiu",
        "outputId": "b5a1acb4-452b-4b71-9e28-997895dce0f7"
      },
      "source": [
        "for value in set(y):\r\n",
        "  print(value, ':', list(y).count(value))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : 178\n",
            "1 : 182\n",
            "2 : 177\n",
            "3 : 183\n",
            "4 : 181\n",
            "5 : 182\n",
            "6 : 181\n",
            "7 : 179\n",
            "8 : 174\n",
            "9 : 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUEtV94bk0Kh"
      },
      "source": [
        "Como a ocorrência é cada classe é um pouco diferente, podemos realizar uma *undersampling* das classes maiores e deixar todas com a mesma contagem de exemplos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u703L3gM4hrH",
        "outputId": "c448df92-dfc7-401f-a601-264bfc3c1eba"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\r\n",
        "\r\n",
        "rus = RandomUnderSampler()\r\n",
        "\r\n",
        "X_rus, y_rus = rus.fit_resample(X, y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtxag1ebNn_X",
        "outputId": "8518ddff-d244-41bd-9983-6987796a0421"
      },
      "source": [
        "for value in set(y_rus):\r\n",
        "  print(value, ':', list(y_rus).count(value))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : 174\n",
            "1 : 174\n",
            "2 : 174\n",
            "3 : 174\n",
            "4 : 174\n",
            "5 : 174\n",
            "6 : 174\n",
            "7 : 174\n",
            "8 : 174\n",
            "9 : 174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQNfbMG0lBGG"
      },
      "source": [
        "Agora vamos segmentar nosso *dataset* em uma fração de treino e outra de teste (ou validação)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUEfIhx75Qu5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6gqMU-dlIcL"
      },
      "source": [
        "Quando trabalhamos com redes neurais é uma boa prática se realizar o ajuste dos valores de entrada para estes estejam em um mesmo intervalo e (preferencialmente) entre 0 e 1 ou -1 e 1. Dados com amplitudes maiores podem dificultar o processo de amprendizagem. \r\n",
        "\r\n",
        "**Nota:** o processo de ajuste de escala e / ou normalização deve ser realizado APÓS a separação dos dados de treino dos dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfg9C1UF5p8T"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "\r\n",
        "X_train_scaled = scaler.transform(X_train)\r\n",
        "X_test_scaled  = scaler.transform(X_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzAjviyqN91t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ffdfcfe-8b79-4778-f1ed-7ebfb69aec34"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  2., ...,  3.,  0.,  0.],\n",
              "       [ 0.,  0.,  1., ..., 14.,  9.,  0.],\n",
              "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "       ...,\n",
              "       [ 0.,  0., 10., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  1., 11., ...,  8.,  0.,  0.],\n",
              "       [ 0.,  1., 11., ...,  8.,  1.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krk2rwPON_mJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be961be-3ae0-4bed-95ef-a2d70d84b25e"
      },
      "source": [
        "X_train_scaled"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        , -0.32886482, -0.66734446, ..., -0.65995299,\n",
              "        -0.52103478, -0.20026919],\n",
              "       [ 0.        , -0.32886482, -0.87851917, ...,  1.1961648 ,\n",
              "         1.63982451, -0.20026919],\n",
              "       [ 0.        , -0.32886482, -1.08969389, ..., -1.16616694,\n",
              "        -0.52103478, -0.20026919],\n",
              "       ...,\n",
              "       [ 0.        , -0.32886482,  1.02205325, ..., -1.16616694,\n",
              "        -0.52103478, -0.20026919],\n",
              "       [ 0.        ,  0.77723978,  1.23322797, ...,  0.18373691,\n",
              "        -0.52103478, -0.20026919],\n",
              "       [ 0.        ,  0.77723978,  1.23322797, ...,  0.18373691,\n",
              "        -0.28093931, -0.20026919]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEynj80dtSTD"
      },
      "source": [
        "## Criando uma rede neural com o PyTorch\r\n",
        "\r\n",
        "Agora podemos criar uma rede neural usando como base a classe `torch.nn.Module`. Para isso definimos cada camada em um atributo de classe no método construtor (`__init__`), para serem iniciadas quando esta forma intanciada, e depois definimos as conexões entre elas no método `forward`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KwfWOXrtllc"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "      super(Net, self).__init__()\r\n",
        "      self.fc1 = nn.Linear(64, 32)\r\n",
        "      self.fc2 = nn.Linear(32, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "      x = self.fc1(x)\r\n",
        "      x = F.relu(x)\r\n",
        "      x = self.fc2(x)\r\n",
        "      return F.softmax(x)\r\n",
        "\r\n",
        "model = Net()\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca087Z1tmiM0"
      },
      "source": [
        "Agora definimos os nossos ciclos de treinamento, chamados \"épocas\" (`epochs`). Cada época consiste em uma leitura completa do *dataset* e inclui o ajuste dos pesos pelo nosso otimizador. É possível também se dividir uma época em passos (*steps*), onde os pesos serão ajustados com base em segmentos do *dataset* denominados *mini-batches*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "pRnn5H_eue5J",
        "outputId": "0ffd5b45-9388-43ef-d9c1-cd2c348d0007"
      },
      "source": [
        "loss_history = []\r\n",
        "\r\n",
        "for epoch in range(1000):\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    inputs = torch.from_numpy(X_train_scaled).float()\r\n",
        "    labels = torch.from_numpy(y_train)\r\n",
        "\r\n",
        "    outputs = model(inputs)\r\n",
        "    loss = criterion(outputs, labels)\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    loss_history.append(loss.item())\r\n",
        "\r\n",
        "plt.plot(loss_history)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f802f8664d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xutMP6M5vHXx"
      },
      "source": [
        "Agora podemos avaliar o nosso modelo com base nos dados de teste. Primeiro vamos avaliar a acurácia \"global\" do modelo usando a função `accuracy_score` do módulo `sklearn.metrics`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2wQ7aU24Aoz",
        "outputId": "cbc24013-8da5-4cd2-83f4-f08624dfad95"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "\r\n",
        "  inputs = torch.from_numpy(X_test_scaled).float()\r\n",
        "  outputs = model(inputs) \r\n",
        "  y_pred  = np.argmax(outputs.data.numpy(), axis=1)\r\n",
        "\r\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9448275862068966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_bIJmYKvVkj"
      },
      "source": [
        "Agora vamos criar uma \"matriz de confusão\" usando a função `confusion_matrix` do mesmo módulo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wanq0EY0kMcY",
        "outputId": "ad592140-af28-4e4a-d144-9399ea9c2844"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "cm = confusion_matrix(y_test, y_pred)\r\n",
        "cm"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[52,  0,  0,  0,  0,  0,  1,  0,  0,  0],\n",
              "       [ 0, 38,  7,  0,  0,  0,  1,  0,  0,  7],\n",
              "       [ 0,  0, 38,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0,  0,  0, 40,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0,  0,  0,  0, 47,  0,  0,  0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0, 42,  0,  0,  0,  0],\n",
              "       [ 2,  0,  0,  0,  0,  0, 34,  0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 52,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  1, 35,  1],\n",
              "       [ 0,  0,  0,  0,  0,  1,  0,  0,  3, 33]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcZn-CL7vctz"
      },
      "source": [
        "Por fim, vamos utilizar o `classification_report` para entender melhor qual a precisão e o *recall* do nosso modelo para cada classe. Estas informações ficam implícitas na matriz de confusão, mas sempre é bom ter elas de uma forma mais direta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK-ugCbOuF3s",
        "outputId": "def41ccd-82e6-471d-f599-aa1cabdb1737"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9630    0.9811    0.9720        53\n",
            "           1     1.0000    0.7170    0.8352        53\n",
            "           2     0.8444    1.0000    0.9157        38\n",
            "           3     1.0000    1.0000    1.0000        40\n",
            "           4     1.0000    1.0000    1.0000        47\n",
            "           5     0.9767    1.0000    0.9882        42\n",
            "           6     0.9444    0.9444    0.9444        36\n",
            "           7     0.9811    1.0000    0.9905        52\n",
            "           8     0.9211    0.9459    0.9333        37\n",
            "           9     0.8049    0.8919    0.8462        37\n",
            "\n",
            "    accuracy                         0.9448       435\n",
            "   macro avg     0.9436    0.9480    0.9425       435\n",
            "weighted avg     0.9495    0.9448    0.9435       435\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "YntQVGxTwV5o",
        "outputId": "4c28a235-f3e4-450c-8824-b5757c027828"
      },
      "source": [
        "example = 210\r\n",
        "\r\n",
        "X_test_example = X_test[example]\r\n",
        "plot_digit(X_test_example)\r\n",
        "\r\n",
        "X_test_example_tensor = torch.from_numpy(X_test_example).float()\r\n",
        "output = model(X_test_example_tensor)\r\n",
        "y_test_example = y_test[example]\r\n",
        "y_pred_example = np.argmax(output.data.numpy())\r\n",
        "\r\n",
        "print('real label:     ', y_test_example)\r\n",
        "print('predicted label:', y_pred_example)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "real label:      4\n",
            "predicted label: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}